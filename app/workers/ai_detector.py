# app/workers/ai_detector.py
import os
import sys
import time
import signal
import numpy as np
from multiprocessing import Queue

# C·∫•u h√¨nh m√¥i tr∆∞·ªùng: T·∫Øt log r√°c c·ªßa OpenCV
os.environ["OPENCV_LOG_LEVEL"] = "OFF"
os.environ["FOR_DISABLE_CONSOLE_CTRL_HANDLER"] = "1"

# Import OpenCV
try: import cv2
except ImportError: cv2 = None

# Import YOLO (Optional)
try: from ultralytics import YOLO
except ImportError: YOLO = None

# Import Pyzbar (Optional)
try:
    from pyzbar import pyzbar
    from pyzbar.pyzbar import ZBarSymbol
except ImportError:
    pyzbar = None

def run_ai_process(input_queue: Queue, output_queue: Queue, model_path: str):
    """
    Ti·∫øn tr√¨nh AI ch·∫°y ƒë·ªôc l·∫≠p.
    Nhi·ªám v·ª•: Ph√°t hi·ªán ng∆∞·ªùi (YOLO) & Gi·∫£i m√£ QR/Barcode (Pyzbar Multi-pass).
    """
    
    # B·ªè qua t√≠n hi·ªáu Ctrl+C ƒë·ªÉ ti·∫øn tr√¨nh cha qu·∫£n l√Ω vi·ªác d·ª´ng
    try: signal.signal(signal.SIGINT, signal.SIG_IGN)
    except: pass

    print(f"ü§ñ [AI Process] Started. PID: {os.getpid()}")
    
    # 1. Load YOLO Model
    model = None
    if YOLO:
        try: 
            # Load model, chuy·ªÉn sang CPU n·∫øu kh√¥ng c√≥ GPU
            model = YOLO(model_path)
            print(f"‚úÖ [AI Process] YOLO Model '{model_path}' Loaded.")
        except Exception as e: 
            print(f"‚ö†Ô∏è [AI Process] YOLO Error: {e}")

    # 2. Kh·ªüi t·∫°o c√¥ng c·ª• x·ª≠ l√Ω ·∫£nh
    clahe = None
    if cv2 is not None:
        # CLAHE gi√∫p c√¢n b·∫±ng s√°ng c·ª•c b·ªô, t·ªët cho m√£ b·ªã t·ªëi g√≥c
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

    while True:
        try:
            try:
                frame_data = input_queue.get(timeout=0.1)
            except:
                continue
            
            img = frame_data.get('image')
            cam_id = frame_data.get('cam_id')
            target_w = frame_data.get('target_w', 1280)
            target_h = frame_data.get('target_h', 720)
            
            if img is None: continue

            # T√≠nh t·ª∑ l·ªá scale
            h_input, w_input = img.shape[:2]
            scale_x = target_w / w_input if w_input > 0 else 1.0
            scale_y = target_h / h_input if h_input > 0 else 1.0

            detections = []

            # ==================================================================
            # 1. HUMAN DETECTION (YOLO)
            # ==================================================================
            if model:
                # imgsz=480 gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω tr√™n Orange Pi
                results = model.predict(img, imgsz=480, conf=0.45, verbose=False, classes=[0], device='cpu')
                for r in results:
                    for box in r.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].tolist()
                        detections.append({
                            "type": "human",
                            "box": [
                                int(x1 * scale_x), int(y1 * scale_y), 
                                int((x2 - x1) * scale_x), int((y2 - y1) * scale_y)
                            ], 
                            "label": f"Human {int(box.conf[0]*100)}%",
                            "color": "#e74c3c"
                        })

            # ==================================================================
            # 2. QR CODE / BARCODE DETECTION (Chi·∫øn thu·∫≠t 4 L·ªõp)
            # [FIX] T·ªëi ∆∞u h√≥a ƒë·ªÉ ch·ªëng ch√≥i v√† √°nh s√°ng m·∫°nh
            # ==================================================================
            if pyzbar and cv2:
                # Chuy·ªÉn ·∫£nh x√°m
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                decoded = []

                # --- L·ªõp 1: ·∫¢nh g·ªëc (Nhanh nh·∫•t) ---
                # D√†nh cho tr∆∞·ªùng h·ª£p √°nh s√°ng ho√†n h·∫£o
                decoded = pyzbar.decode(gray, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])
                
                # --- L·ªõp 2: Adaptive Threshold (Ch·ªëng Ch√≥i/B√≥ng) ---
                # [QUAN TR·ªåNG] C√°i n√†y fix l·ªói b·∫≠t ƒë√®n c·ªßa b·∫°n.
                # N√≥ t√≠nh ng∆∞·ª°ng ri√™ng cho t·ª´ng v√πng nh·ªè, gi√∫p ƒë·ªçc ƒë∆∞·ª£c m√£ d√π n·ªÅn b·ªã s√°ng r·ª±c.
                if not decoded:
                    gray_adaptive = cv2.adaptiveThreshold(
                        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                        cv2.THRESH_BINARY, 21, 10
                    )
                    decoded = pyzbar.decode(gray_adaptive, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])

                # --- L·ªõp 3: Otsu's Binarization (T·ª± ƒë·ªông t√¨m ng∆∞·ª°ng) ---
                # Thay th·∫ø cho ng∆∞·ª°ng c·ª©ng 90. Otsu t·ª± t√¨m ng∆∞·ª°ng t·ªëi ∆∞u (v√≠ d·ª• 120, 150)
                # D√†nh cho tr∆∞·ªùng h·ª£p ƒë·ªô t∆∞∆°ng ph·∫£n th·∫•p.
                if not decoded:
                    _, gray_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                    decoded = pyzbar.decode(gray_otsu, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])

                # --- L·ªõp 4: CLAHE (TƒÉng t∆∞∆°ng ph·∫£n) ---
                # D√†nh cho tr∆∞·ªùng h·ª£p m√£ n·∫±m trong b√≥ng t·ªëi ho·∫∑c g√≥c khu·∫•t
                if not decoded and clahe:
                    gray_clahe = clahe.apply(gray)
                    # Sau khi tƒÉng t∆∞∆°ng ph·∫£n th√¨ Otsu l·∫°i m·ªôt l·∫ßn n·ªØa
                    _, gray_clahe_otsu = cv2.threshold(gray_clahe, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                    decoded = pyzbar.decode(gray_clahe_otsu, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])

                # --- X·ª≠ l√Ω k·∫øt qu·∫£ gi·∫£i m√£ ---
                for obj in decoded:
                    try:
                        code_content = obj.data.decode("utf-8")
                        x, y, w, h = obj.rect
                        
                        detections.append({
                            "type": "qrcode",
                            "box": [
                                int(x * scale_x), int(y * scale_y), 
                                int(w * scale_x), int(h * scale_y)
                            ],
                            "label": code_content,
                            "code": code_content, 
                            "code_type": obj.type,
                            "color": "#2ecc71"
                        })
                    except: pass

            # Tr·∫£ k·∫øt qu·∫£
            if not output_queue.full():
                output_queue.put({'cam_id': cam_id, 'data': detections})

        except KeyboardInterrupt:
            break
        except Exception: 
            continue
            
    print("üõë [AI Process] Stopped.")