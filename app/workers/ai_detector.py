# app/workers/ai_detector.py
import os
import sys
import time
import signal
import numpy as np
from multiprocessing import Queue

# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENCV_LOG_LEVEL"] = "OFF"

# 1. IMPORT OPENCV
try: 
    import cv2
    print("‚úÖ [AI Check] OpenCV imported successfully.")
except ImportError as e: 
    cv2 = None
    print(f"‚ùå [AI Check] OpenCV MISSING: {e}")

# 2. IMPORT YOLO (HUMAN DETECTION)
try: 
    from ultralytics import YOLO
    import torch
    torch.set_num_threads(1)
    HAS_YOLO = True
    print("‚úÖ [AI Check] Ultralytics (YOLO) imported successfully.")
except ImportError as e: 
    YOLO = None
    HAS_YOLO = False
    print(f"‚ùå [AI Check] Ultralytics MISSING (No Human Detect): {e}")

# 3. IMPORT PYZBAR (QR/BARCODE)
try:
    from pyzbar import pyzbar
    from pyzbar.pyzbar import ZBarSymbol
    HAS_ZBAR = True
    print("‚úÖ [AI Check] Pyzbar imported successfully.")
except ImportError as e:
    pyzbar = None
    HAS_ZBAR = False
    print(f"‚ùå [AI Check] Pyzbar MISSING. Run 'apt install libzbar0'. Error: {e}")

def run_ai_process(input_queue: Queue, output_queue: Queue, model_path: str):
    """
    Ti·∫øn tr√¨nh AI ƒë·ªôc l·∫≠p: X·ª≠ l√Ω QR Code v√† Ph√°t hi·ªán ng∆∞·ªùi (Human Detection)
    """
    # B·ªè qua t√≠n hi·ªáu Interrupt ƒë·ªÉ ti·∫øn tr√¨nh cha (Main) qu·∫£n l√Ω vi·ªác ƒë√≥ng
    try: signal.signal(signal.SIGINT, signal.SIG_IGN)
    except: pass

    print(f"ü§ñ [AI Process] Started. PID: {os.getpid()}")
    
    # --- LOAD MODEL YOLO ---
    model = None
    if HAS_YOLO:
        if os.path.exists(model_path):
            try: 
                model = YOLO(model_path)
                print(f"‚úÖ [AI Process] YOLO Model Loaded: {model_path}")
            except Exception as e: 
                print(f"‚ùå [AI Process] Failed to load YOLO: {e}")
        else:
            print(f"‚ùå [AI Process] Weights not found: {model_path}")

    # Ma tr·∫≠n l√†m n√©t ·∫£nh (Laplacian-based sharpen)
    sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    
    # Kh·ªüi t·∫°o b·ªô c√¢n b·∫±ng √°nh s√°ng c·ª•c b·ªô (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)) if cv2 else None

    while True:
        try:
            try:
                # L·∫•y d·ªØ li·ªáu t·ª´ h√†ng ƒë·ª£i (timeout ƒë·ªÉ tr√°nh treo ti·∫øn tr√¨nh)
                frame_data = input_queue.get(timeout=0.1)
            except:
                continue
            
            img = frame_data.get('image')
            cam_id = frame_data.get('cam_id')
            target_w = frame_data.get('target_w', 1280)
            target_h = frame_data.get('target_h', 720)
            
            if img is None: continue

            # T√≠nh to√°n t·ªâ l·ªá scale ƒë·ªÉ tr·∫£ v·ªÅ t·ªça ƒë·ªô ch√≠nh x√°c cho UI
            h_input, w_input = img.shape[:2]
            scale_x = target_w / w_input if w_input > 0 else 1.0
            scale_y = target_h / h_input if h_input > 0 else 1.0

            detections = []
            
            # ------------------------------------------------------------------
            # 1. X·ª¨ L√ù QU√âT M√É (QR CODE & BARCODE)
            # ------------------------------------------------------------------
            if HAS_ZBAR and cv2:
                try:
                    # Chuy·ªÉn x√°m v√† tƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n
                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                    gray_enhanced = clahe.apply(gray) if clahe else gray
                    
                    # L√†m n√©t ƒë·ªÉ c√°c v·∫°ch m√£ r√µ r√†ng h∆°n
                    gray_sharp = cv2.filter2D(gray_enhanced, -1, sharpen_kernel)
                    
                    # Th·ª≠ qu√©t l·∫ßn 1: To√†n m√†n h√¨nh
                    decoded_objects = pyzbar.decode(gray_sharp, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])
                    
                    # N·∫øu kh√¥ng th·∫•y -> Th·ª≠ Zoom 1.5x v√πng trung t√¢m (gi·ªØ nguy√™n t·ªâ l·ªá)
                    if not decoded_objects:
                        crop_h, crop_w = int(h_input * 0.7), int(w_input * 0.7)
                        start_y, start_x = (h_input - crop_h) // 2, (w_input - crop_w) // 2
                        
                        roi = gray_enhanced[start_y:start_y+crop_h, start_x:start_x+crop_w]
                        
                        # Ph√≥ng to v√πng trung t√¢m b·∫±ng n·ªôi suy Cubic ƒë·ªÉ gi·ªØ ƒë·ªô s·∫Øc n√©t
                        roi_zoomed = cv2.resize(roi, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)
                        roi_zoomed_sharp = cv2.filter2D(roi_zoomed, -1, sharpen_kernel)
                        
                        decoded_roi = pyzbar.decode(roi_zoomed_sharp, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])
                        
                        for obj in decoded_roi:
                            content = obj.data.decode("utf-8")
                            zx, zy, zw, zh = obj.rect
                            
                            # Map t·ªça ƒë·ªô t·ª´ ·∫£nh Zoom v·ªÅ ·∫£nh g·ªëc ban ƒë·∫ßu
                            real_roi_x, real_roi_y = int(zx / 1.5), int(zy / 1.5)
                            real_roi_w, real_roi_h = int(zw / 1.5), int(zh / 1.5)
                            
                            final_x = start_x + real_roi_x
                            final_y = start_y + real_roi_y
                            
                            detections.append({
                                "type": "qrcode",
                                "box": [
                                    int(final_x * scale_x), int(final_y * scale_y), 
                                    int(real_roi_w * scale_x), int(real_roi_h * scale_y)
                                ],
                                "label": content,
                                "code": content, 
                                "code_type": str(obj.type),
                                "color": "#2ecc71"
                            })
                    else:
                        # K·∫øt qu·∫£ qu√©t to√†n m√†n h√¨nh th√†nh c√¥ng
                        for obj in decoded_objects:
                            content = obj.data.decode("utf-8")
                            x, y, w, h = obj.rect
                            detections.append({
                                "type": "qrcode",
                                "box": [
                                    int(x * scale_x), int(y * scale_y), 
                                    int(w * scale_x), int(h * scale_y)
                                ],
                                "label": content,
                                "code": content, 
                                "code_type": str(obj.type),
                                "color": "#2ecc71"
                            })
                except Exception as e:
                    print(f"‚ö†Ô∏è [AI QR] Scan Error: {e}")

            # ------------------------------------------------------------------
            # 2. X·ª¨ L√ù PH√ÅT HI·ªÜN NG∆Ø·ªúI (HUMAN DETECTION)
            # ------------------------------------------------------------------
            if model:
                try:
                    # Predict v·ªõi imgsz nh·ªè ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô tr√™n CPU (Orange Pi/PC)
                    results = model.predict(img, imgsz=320, conf=0.5, verbose=False, classes=[0], device='cpu')
                    for r in results:
                        for box in r.boxes:
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            detections.append({
                                "type": "human",
                                "box": [
                                    int(x1 * scale_x), int(y1 * scale_y), 
                                    int((x2 - x1) * scale_x), int((y2 - y1) * scale_y)
                                ], 
                                "label": f"Human {int(box.conf[0]*100)}%",
                                "color": "#e74c3c"
                            })
                except Exception as e:
                    print(f"‚ö†Ô∏è [AI YOLO] Error: {e}")

            # G·ª≠i to√†n b·ªô metadata ph√°t hi·ªán ƒë∆∞·ª£c v·ªÅ Main Process
            if not output_queue.full():
                output_queue.put({'cam_id': cam_id, 'data': detections})

        except KeyboardInterrupt:
            break
        except Exception as e: 
            print(f"‚ö†Ô∏è [AI Process] Loop Error: {e}")
            continue
            
    print("üõë [AI Process] Stopped.")