# app/workers/ai_detector.py
import os
import sys
import time
import signal
import numpy as np
from multiprocessing import Queue

# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENCV_LOG_LEVEL"] = "OFF"

# 1. IMPORT OPENCV
try: 
    import cv2
    print("‚úÖ [AI Check] OpenCV imported successfully.")
except ImportError as e: 
    cv2 = None
    print(f"‚ùå [AI Check] OpenCV MISSING: {e}")

# 2. IMPORT YOLO (HUMAN DETECTION)
try: 
    from ultralytics import YOLO
    import torch
    torch.set_num_threads(1)
    HAS_YOLO = True
    print("‚úÖ [AI Check] Ultralytics (YOLO) imported successfully.")
except ImportError as e: 
    YOLO = None
    HAS_YOLO = False
    print(f"‚ùå [AI Check] Ultralytics MISSING (No Human Detect): {e}")

# 3. IMPORT PYZBAR (QR/BARCODE)
try:
    from pyzbar import pyzbar
    from pyzbar.pyzbar import ZBarSymbol
    HAS_ZBAR = True
    print("‚úÖ [AI Check] Pyzbar imported successfully.")
except ImportError as e:
    pyzbar = None
    HAS_ZBAR = False
    print(f"‚ùå [AI Check] Pyzbar MISSING. Run 'apt install libzbar0'. Error: {e}")

def run_ai_process(input_queue: Queue, output_queue: Queue, model_path: str):
    """
    Ti·∫øn tr√¨nh AI ƒë·ªôc l·∫≠p: X·ª≠ l√Ω QR Code (3 L·ªõp) v√† Ph√°t hi·ªán ng∆∞·ªùi
    """
    try: signal.signal(signal.SIGINT, signal.SIG_IGN)
    except: pass

    print(f"ü§ñ [AI Process] Started. PID: {os.getpid()}")
    
    # --- LOAD MODEL YOLO ---
    model = None
    if HAS_YOLO:
        if os.path.exists(model_path):
            try: 
                model = YOLO(model_path)
                print(f"‚úÖ [AI Process] YOLO Model Loaded: {model_path}")
            except Exception as e: 
                print(f"‚ùå [AI Process] Failed to load YOLO: {e}")
        else:
            print(f"‚ùå [AI Process] Weights not found: {model_path}")
    
    # Kh·ªüi t·∫°o b·ªô c√¢n b·∫±ng √°nh s√°ng c·ª•c b·ªô (CLAHE) - Gi√∫p ƒë·ªçc m√£ in m·ªù/b√≥ng
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)) if cv2 else None

    while True:
        try:
            try:
                frame_data = input_queue.get(timeout=0.1)
            except:
                continue
            
            img = frame_data.get('image')
            cam_id = frame_data.get('cam_id')
            target_w = frame_data.get('target_w', 1280)
            target_h = frame_data.get('target_h', 720)
            
            if img is None: continue

            h_input, w_input = img.shape[:2]
            scale_x = target_w / w_input if w_input > 0 else 1.0
            scale_y = target_h / h_input if h_input > 0 else 1.0

            detections = []
            
            # ------------------------------------------------------------------
            # 1. X·ª¨ L√ù QU√âT M√É (CHI·∫æN THU·∫¨T 3 L·ªöP)
            # ------------------------------------------------------------------
            if HAS_ZBAR and cv2:
                try:
                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                    
                    # --- L·ªöP 1: Qu√©t nhanh ·∫£nh g·ªëc (D√†nh cho m√£ to, r√µ) ---
                    decoded_objects = pyzbar.decode(gray, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])
                    
                    found_in_zoom = False
                    
                    # --- L·ªöP 2: Zoom & Enhance (D√†nh cho m√£ nh·ªè, xa) ---
                    if not decoded_objects:
                        # C·∫Øt v√πng trung t√¢m 60%
                        crop_ratio = 0.6
                        crop_h, crop_w = int(h_input * crop_ratio), int(w_input * crop_ratio)
                        start_y, start_x = (h_input - crop_h) // 2, (w_input - crop_w) // 2
                        
                        roi = gray[start_y:start_y+crop_h, start_x:start_x+crop_w]
                        
                        # Ph√≥ng to 2x (Upscale) ƒë·ªÉ m√£ r√µ h∆°n
                        # D√πng INTER_LINEAR nhanh h∆°n v√† m∆∞·ª£t h∆°n cho m√£ v·∫°ch
                        zoom_factor = 2.0
                        roi_zoomed = cv2.resize(roi, None, fx=zoom_factor, fy=zoom_factor, interpolation=cv2.INTER_LINEAR)
                        
                        # TƒÉng t∆∞∆°ng ph·∫£n c·ª•c b·ªô (CLAHE)
                        roi_enhanced = clahe.apply(roi_zoomed) if clahe else roi_zoomed
                        
                        decoded_roi = pyzbar.decode(roi_enhanced, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])
                        
                        # --- L·ªöP 3: Thresholding (D√†nh cho m√£ in m·ªù, gi·∫•y than) ---
                        if not decoded_roi:
                            # Nh·ªã ph√¢n h√≥a: Bi·∫øn ·∫£nh th√†nh ƒëen/tr·∫Øng ho√†n to√†n
                            # Block size 21, C=4 gi√∫p l·ªçc nhi·ªÖu n·ªÅn gi·∫•y t·ªët
                            roi_bin = cv2.adaptiveThreshold(roi_enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 4)
                            decoded_roi = pyzbar.decode(roi_bin, symbols=[ZBarSymbol.QRCODE, ZBarSymbol.CODE128])

                        # N·∫øu t√¨m th·∫•y ·ªü l·ªõp 2 ho·∫∑c 3, map t·ªça ƒë·ªô v·ªÅ ·∫£nh g·ªëc
                        if decoded_roi:
                            found_in_zoom = True
                            for obj in decoded_roi:
                                content = obj.data.decode("utf-8")
                                zx, zy, zw, zh = obj.rect
                                
                                # T√≠nh ng∆∞·ª£c t·ªça ƒë·ªô t·ª´ ·∫£nh Zoom v·ªÅ ·∫£nh G·ªëc
                                real_roi_x = int(zx / zoom_factor)
                                real_roi_y = int(zy / zoom_factor)
                                real_roi_w = int(zw / zoom_factor)
                                real_roi_h = int(zh / zoom_factor)
                                
                                final_x = start_x + real_roi_x
                                final_y = start_y + real_roi_y
                                
                                detections.append({
                                    "type": "qrcode",
                                    "box": [
                                        int(final_x * scale_x), int(final_y * scale_y), 
                                        int(real_roi_w * scale_x), int(real_roi_h * scale_y)
                                    ],
                                    "label": content,
                                    "code": content, 
                                    "code_type": str(obj.type),
                                    "color": "#2ecc71"
                                })

                    # X·ª≠ l√Ω k·∫øt qu·∫£ l·ªõp 1 (n·∫øu c√≥)
                    if not found_in_zoom and decoded_objects:
                        for obj in decoded_objects:
                            content = obj.data.decode("utf-8")
                            x, y, w, h = obj.rect
                            detections.append({
                                "type": "qrcode",
                                "box": [
                                    int(x * scale_x), int(y * scale_y), 
                                    int(w * scale_x), int(h * scale_y)
                                ],
                                "label": content,
                                "code": content, 
                                "code_type": str(obj.type),
                                "color": "#2ecc71"
                            })
                            
                except Exception as e:
                    print(f"‚ö†Ô∏è [AI QR] Scan Error: {e}")

            # ------------------------------------------------------------------
            # 2. X·ª¨ L√ù PH√ÅT HI·ªÜN NG∆Ø·ªúI (HUMAN DETECTION)
            # ------------------------------------------------------------------
            if model:
                try:
                    # Predict v·ªõi imgsz nh·ªè (320) ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô CPU
                    results = model.predict(img, imgsz=320, conf=0.5, verbose=False, classes=[0], device='cpu')
                    for r in results:
                        for box in r.boxes:
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            detections.append({
                                "type": "human",
                                "box": [
                                    int(x1 * scale_x), int(y1 * scale_y), 
                                    int((x2 - x1) * scale_x), int((y2 - y1) * scale_y)
                                ], 
                                "label": f"Human {int(box.conf[0]*100)}%",
                                "color": "#e74c3c"
                            })
                except Exception as e:
                    print(f"‚ö†Ô∏è [AI YOLO] Error: {e}")

            # G·ª≠i d·ªØ li·ªáu v·ªÅ Main Process
            if not output_queue.full():
                output_queue.put({'cam_id': cam_id, 'data': detections})

        except KeyboardInterrupt:
            break
        except Exception as e: 
            print(f"‚ö†Ô∏è [AI Process] Loop Error: {e}")
            continue
            
    print("üõë [AI Process] Stopped.")