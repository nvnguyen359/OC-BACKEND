# app/workers/camera_worker.py
import os
import sys
import threading
import time
import multiprocessing
import platform
import signal
import psutil
from datetime import datetime, timedelta
from typing import Dict, Optional, Any
import pytz

# --- 1. IMPORTS MODULES CHUYÃŠN BIá»†T ---
from app.workers.camera_stream import CameraStream
from app.workers.image_processor import ImageProcessor
from app.workers.video_recorder import VideoRecorder

# --- 2. IMPORTS Há»† THá»NG KHÃC ---
from app.workers.ai_detector import run_ai_process
from app.workers.packing_machine import PackingStateMachine, MachineState, Action
from app.services.order_repository import order_repo
from app.services.media_service import media_service
from app.core.resolution_loader import get_system_resolution
from app.core.oc_enums import OrderStatus, OrderNote
from app.crud.setting_crud import setting as setting_crud
from app.db.session import SessionLocal

# [NEW] Import dá»‹ch vá»¥ TTS
from app.services.google_tts import tts_service

# --- Cáº¤U HÃŒNH ---
os.environ["OPENCV_LOG_LEVEL"] = "OFF"
FPS_RECORD = 20.0
RECONNECT_DELAY = 5.0

# =============================================================================
# HELPER: PHÃT Ã‚M THANH
# =============================================================================
def play_audio_alert(file_path: str):
    def _run():
        try:
            if not os.path.exists(file_path): return
            if platform.system() == "Linux":
                os.system(f"mpg123 -q {file_path} &")
            elif platform.system() == "Windows":
                import winsound
                winsound.PlaySound(file_path, winsound.SND_FILENAME)
        except: pass
    threading.Thread(target=_run, daemon=True).start()

# =============================================================================
# CLASS: CAMERA RUNTIME
# =============================================================================
class CameraRuntime:
    def __init__(self, cam_id: int, source: Any, ai_queue: multiprocessing.Queue):
        self.cam_id = cam_id
        self.ai_queue = ai_queue
        
        # 1. Load Cáº¥u hÃ¬nh
        self.target_w, self.target_h = get_system_resolution()
        print(f"ðŸ”§ [Cam {cam_id}] Target Res: {self.target_w}x{self.target_h}")

        # 2. Modules con
        self.stream = CameraStream(source, cam_id)
        self.img_proc = ImageProcessor()
        self.recorder = VideoRecorder(fps=FPS_RECORD)
        self.machine = PackingStateMachine()

        # 3. Tráº¡ng thÃ¡i
        self.is_running = False
        self.is_connected = False
        self.thread = None
        self.lock = threading.Lock()
        
        # Dá»¯ liá»‡u áº£nh
        self.jpeg_bytes = None
        self.raw_frame_for_ai = None
        self.ai_metadata = []
        
        # Biáº¿n báº¯n sá»± kiá»‡n qua WebSocket (náº¿u cÃ³ client káº¿t ná»‘i)
        self.stream_metadata = {} 
        
        # Biáº¿n UI
        self.last_scanned_code = None
        self.last_scanned_time = 0
        
        # Dá»¯ liá»‡u ÄÆ¡n hÃ ng
        self.current_order_db_id = None
        self.rec_start_time = 0
        self.code_context_cache = {}
        
        # Audio Cooldown
        self.last_scan_audio_time = 0
        self.SCAN_AUDIO_COOLDOWN = 3.0

        # TTS Config
        self.read_end_digits_count = 5
        self.last_spoken_code = None

        self._load_and_apply_settings()
        self.start()

    @property
    def recording(self) -> bool:
        return self.machine.state == MachineState.PACKING

    def _emit_event(self, event_name, data):
        # Chá»‰ cáº­p nháº­t metadata, Front-end nÃ o connect thÃ¬ tá»± láº¥y
        self.stream_metadata = {
            "event": event_name,
            "data": data,
            "ts": time.time()
        }

    def _load_and_apply_settings(self):
        try:
            db = SessionLocal()
            settings = setting_crud.get_all_as_dict(db)
            db.close()
            timeout = int(settings.get("timeout_no_human", "60"))
            end_time = settings.get("work_end_time", "18:30")
            self.read_end_digits_count = int(settings.get("read_end_order", "5"))
            
            self.machine.update_config(timeout, end_time)
            print(f"âš™ï¸ [Cam {self.cam_id}] Config: Timeout={timeout}s, EndShift={end_time}, ReadEnd={self.read_end_digits_count}")
        except Exception as e: print(f"âš ï¸ Settings Err: {e}")

    # --- CONTROL ---
    def start(self):
        """Khá»Ÿi Ä‘á»™ng luá»“ng xá»­ lÃ½ camera"""
        if self.is_running: return
        self.is_running = True
        # Daemon=True giÃºp thread tá»± táº¯t khi app chÃ­nh táº¯t
        self.thread = threading.Thread(target=self._capture_loop, daemon=True)
        self.thread.start()

    def stop(self):
        self.is_running = False
        if self.thread: self.thread.join(timeout=2.0)
        self._do_stop_order(self.machine.current_code, OrderNote.SYSTEM_RESTART)
        self.stream.release()
        with self.lock: self.is_connected = False

    def start_recording(self, code):
        print(f"ðŸ”´ Force Start: {code}")
        if self.machine.force_start(code) == Action.START_ORDER:
            self._do_start_order(code, note=OrderNote.MANUAL)

    def stop_recording(self):
        print(f"âšª Force Stop")
        action, code = self.machine.manual_stop()
        if action == Action.STOP_ORDER:
            self._do_stop_order(code, OrderNote.MANUAL)

    def get_jpeg(self):
        with self.lock: return self.jpeg_bytes

    def get_snapshot(self):
        with self.lock:
            if self.raw_frame_for_ai is None: return None
            return self.img_proc.to_jpeg(self.raw_frame_for_ai)

    # --- NGHIá»†P Vá»¤ (GIá»® NGUYÃŠN) ---
    def _do_start_order(self, code, parent_id=None, note=None):
        if not code: return
        try:
            print(f"ðŸŸ¢ START REC: {code}")
            self.recorder.start(code, self.target_w, self.target_h)
            self.current_order_db_id = order_repo.create_order(
                code=code, cam_id=self.cam_id, parent_id=parent_id, note=note
            )
            self.rec_start_time = time.time()
            final_note = note or (OrderNote.REPACK if parent_id else OrderNote.NEW_ORDER)
            self._emit_event("ORDER_CREATED", {
                "code": code, 
                "status": OrderStatus.PACKING, 
                "note": final_note, 
                "start_time": self.rec_start_time * 1000,
                "order_id": self.current_order_db_id
            })
        except Exception as e: print(f"âŒ Start Err: {e}")

    def _do_stop_order(self, code, reason):
        print(f"âšª STOP REC: {code} ({reason})")
        video_path = self.recorder.stop()
        if self.current_order_db_id:
            if reason == OrderNote.CHECKING_ONLY:
                order_repo.cancel_order(self.current_order_db_id)
            else:
                order_repo.close_order(self.current_order_db_id, reason)
        if video_path and os.path.exists(video_path):
            vn_time = datetime.utcnow() + timedelta(hours=7)
            media_service.queue_video_conversion(video_path, code, vn_time, self.current_order_db_id)
        self._emit_event("ORDER_STOPPED", {"code": code, "note": reason})
        self.current_order_db_id = None
        self.last_spoken_code = None

    def _do_snapshot(self, frame, code):
        try:
            path = self.recorder.snapshot(frame, code)
            if path and self.current_order_db_id:
                order_repo.update_avatar(self.current_order_db_id, path)
                self._emit_event("ORDER_UPDATED", {"order_id": self.current_order_db_id, "path_avatar": path})
        except: pass

    # --- MAIN LOOP ---
    def _capture_loop(self):
        print(f"ðŸ“· [Cam {self.cam_id}] Loop Started (Background Mode)")
        
        while self.is_running:
            if not self.stream.connect(self.target_w, self.target_h):
                # KhÃ´ng in quÃ¡ nhiá»u log náº¿u máº¥t káº¿t ná»‘i
                if not hasattr(self, '_log_debounce') or time.time() - self._log_debounce > 10:
                    print(f"âš ï¸ [Cam {self.cam_id}] Waiting for signal...")
                    self._log_debounce = time.time()
                with self.lock: self.is_connected = False
                time.sleep(RECONNECT_DELAY)
                continue
            
            print(f"âœ… [Cam {self.cam_id}] Connected & Processing.")
            with self.lock: self.is_connected = True
            
            frame_cnt = 0
            err_cnt = 0

            while self.is_running:
                ret, raw_frame = self.stream.read()
                now = time.time()

                if not ret:
                    err_cnt += 1
                    time.sleep(0.05)
                    if err_cnt > 30: break 
                    continue
                err_cnt = 0

                frame = self.img_proc.smart_resize(raw_frame, self.target_w, self.target_h)
                if frame is None: continue

                frame_cnt += 1
                if frame_cnt % 5 == 0:
                    try:
                        ai_input = self.img_proc.preprocess_for_ai(frame)
                        self.ai_queue.put_nowait({
                            "cam_id": self.cam_id,
                            "image": ai_input,
                            "target_w": self.target_w,
                            "target_h": self.target_h
                        })
                    except: pass

                self._process_logic(now, frame)
                
                # Váº«n váº½ Overlay Ä‘á»ƒ náº¿u báº­t Frontend lÃªn thÃ¬ tháº¥y ngay
                self._draw_overlay(frame)

                if self.machine.state == MachineState.PACKING:
                    self.recorder.write_frame(frame)

                jpeg = self.img_proc.to_jpeg(frame)
                if jpeg:
                    with self.lock:
                        self.jpeg_bytes = jpeg
                        self.raw_frame_for_ai = frame 
                
                time.sleep(0.001)
            
            self.stream.release()

    def _process_logic(self, now, frame):
        meta = list(self.ai_metadata)
        final_codes = [m['code'] for m in meta if m['type'] in ['qrcode','code']]
        human = any(m['type'] == 'human' for m in meta)
        if final_codes: human = True

        if final_codes:
            current_code = final_codes[0]
            self.last_scanned_code = current_code
            self.last_scanned_time = now
            if now - self.last_scan_audio_time > self.SCAN_AUDIO_COOLDOWN:
                self.last_scan_audio_time = now
            if current_code != self.last_spoken_code:
                n = self.read_end_digits_count
                text_to_read = current_code[-n:] if len(current_code) > n else current_code
                tts_service.speak(f"mÃ£ Ä‘Æ¡n {n} sá»‘ cuá»‘i {text_to_read}")
                self.last_spoken_code = current_code

        codes_for_machine = final_codes
        if self.machine.state == MachineState.IDLE and final_codes:
            code = final_codes[0]
            cache = self.code_context_cache.get(code)
            if not cache or (now - cache['ts'] > 600):
                ord_obj = order_repo.get_latest_order_by_code(code)
                is_old = bool(ord_obj)
                pid = ord_obj.parent_id if ord_obj and ord_obj.parent_id else (ord_obj.id if ord_obj else None)
                cache = {'is_old': is_old, 'pid': pid, 'ts': now}
                self.code_context_cache[code] = cache
            
            if cache['is_old']:
                if self.machine.force_start(code) == Action.START_ORDER:
                    self._do_start_order(code, parent_id=cache['pid'])
                    codes_for_machine = []

        state, action, code, reason = self.machine.process(codes_for_machine, human)

        if action == Action.START_ORDER:
            self._do_start_order(code, note=OrderNote.NEW_ORDER)
        elif action == Action.STOP_ORDER:
            note = OrderNote.MANUAL
            if reason == "TIMEOUT": note = OrderNote.TIMEOUT
            elif reason == "END_SHIFT": note = OrderNote.END_SHIFT
            self._do_stop_order(code, note)
        elif action == Action.SNAPSHOT:
            self._do_snapshot(frame, code)
        elif action == Action.SWITCH_ORDER:
            self._do_stop_order(self.machine.last_closed_code, OrderNote.SCAN_NEW)
            self._do_start_order(code, note=OrderNote.NEW_ORDER)

        if state == MachineState.PACKING:
            dur = now - self.machine.packing_start_time
            if 5.5 < dur < 6.5:
                silence = now - self.machine.last_human_seen_time
                if silence > 5.0:
                    print(f"âš ï¸ C4: No human {silence:.1f}s -> Cancel")
                    self.machine.state = MachineState.IDLE
                    self.machine.current_code = None
                    self._do_stop_order(code, OrderNote.CHECKING_ONLY)

    def _draw_overlay(self, frame):
        state = self.machine.state
        if state == MachineState.PACKING and self.machine.current_code:
            text = f"PACKING: {self.machine.current_code}"
            self.img_proc.draw_text(frame, text, 20, 50, (0, 255, 0)) 
        elif self.last_scanned_code and (time.time() - self.last_scanned_time < 2.0):
            text = f"DETECTED: {self.last_scanned_code}"
            self.img_proc.draw_text(frame, text, 20, 50, (0, 255, 255))
        try:
            tz = pytz.timezone('Asia/Ho_Chi_Minh')
            now_s = datetime.now(tz).strftime("%d/%m/%y %I:%M:%S %p")
            self.img_proc.draw_text(frame, now_s, self.target_w - 360, 50, (255, 255, 255))
        except:
            now_s = datetime.now().strftime("%d/%m/%y %H:%M:%S")
            self.img_proc.draw_text(frame, now_s, self.target_w - 280, 50, (255, 255, 255))

# =============================================================================
# SYSTEM
# =============================================================================
class CameraSystem:
    def __init__(self):
        self.cameras: Dict[int, CameraRuntime] = {}
        self.ai_input = multiprocessing.Queue(maxsize=10)
        self.ai_output = multiprocessing.Queue()
        self.system_stats = {"cpu": 0.0, "ram": 0.0, "threads": 0}
        
        self.ai_process = multiprocessing.Process(
            target=run_ai_process, args=(self.ai_input, self.ai_output, "yolov8n.pt"), daemon=True
        )
        self.ai_process.start()
        
        self.is_system_running = True 
        try: signal.signal(signal.SIGINT, lambda s, f: (self.shutdown(), sys.exit(0)))
        except ValueError: pass
        
        threading.Thread(target=self._listen_ai, daemon=True).start()
        threading.Thread(target=self._monitor_resources, daemon=True).start()

        # [NEW] Tá»± Ä‘á»™ng táº£i camera tá»« DB ngay khi System khá»Ÿi táº¡o (DÃ¹ng CRUD)
        threading.Thread(target=self._startup_load_cameras, daemon=True).start()

    def _startup_load_cameras(self):
        """HÃ m cháº¡y ngáº§m Ä‘á»ƒ load camera tá»« DB khi khá»Ÿi Ä‘á»™ng (Sá»­ dá»¥ng CRUD)"""
        time.sleep(2) # Äá»£i DB/Há»‡ thá»‘ng á»•n Ä‘á»‹nh
        print("ðŸ”„ [System] Auto-loading cameras using camera_crud...")
        
        db = SessionLocal()
        try:
            # Import CRUD á»Ÿ Ä‘Ã¢y Ä‘á»ƒ trÃ¡nh lá»—i vÃ²ng láº·p (Circular Import) 
            # vÃ¬ camera_crud cÃ³ thá»ƒ import models, models láº¡i import cÃ¡i gÃ¬ Ä‘Ã³ liÃªn quan
            from app.crud.camera_crud import camera_crud

            # 1. Láº¥y toÃ n bá»™ danh sÃ¡ch camera
            all_cams = camera_crud.get_all(db)
            
            if not all_cams:
                print("âš ï¸ [System] Database chÆ°a cÃ³ camera nÃ o.")
                return

            for cam in all_cams:
                try:
                    # 2. Kiá»ƒm tra Active (dÃ¹ng getattr cho an toÃ n náº¿u model khÃ¡c)
                    is_active = getattr(cam, 'is_active', False)
                    # Hoáº·c check status
                    status = getattr(cam, 'status', 'UNKNOWN')
                    
                    if not is_active and status != 'ACTIVE':
                        continue # Bá» qua camera Ä‘ang táº¯t
                    
                    # 3. Láº¥y thÃ´ng tin connect (connect_str hoáº·c source)
                    src = getattr(cam, 'connect_str', None) or getattr(cam, 'source', None)
                    
                    # Náº¿u chÆ°a cÃ³ source, thá»­ láº¥y ID - 1 (Logic cÅ© cho webcam)
                    if src is None:
                        src = cam.id - 1

                    # Xá»­ lÃ½ chuá»—i sá»‘
                    if str(src).isdigit():
                        src = int(src)
                    
                    print(f"â–¶ï¸ [System] Auto-start Camera ID={cam.id} Source={src}")
                    self.add_camera(cam.id, src)
                    
                except Exception as e:
                    print(f"âŒ [System] Failed to start Cam {cam.id}: {e}")

        except ImportError:
            print("âŒ [System] Lá»—i Import: KhÃ´ng tÃ¬m tháº¥y 'app.crud.camera_crud'. HÃ£y kiá»ƒm tra láº¡i file.")
        except Exception as e:
            print(f"âŒ [System] DB Error: {e}")
        finally:
            db.close()

    def _monitor_resources(self):
        p = psutil.Process()
        while self.is_system_running:
            try:
                self.system_stats = {
                    "cpu": round(p.cpu_percent(), 1),
                    "ram": round(p.memory_info().rss / 1048576, 1),
                    "threads": threading.active_count()
                }
                time.sleep(2)
            except: pass

    def _listen_ai(self):
        while self.is_system_running:
            try:
                r = self.ai_output.get(timeout=0.5)
                if r['cam_id'] in self.cameras:
                    self.cameras[r['cam_id']].ai_metadata = r.get('data', [])
            except: pass

    def add_camera(self, cid, src):
        if cid in self.cameras: 
            print(f"â„¹ï¸ Camera {cid} is already running.")
            return 
            
        self.cameras[cid] = CameraRuntime(cid, src, self.ai_input)
    
    def get_camera(self, cid): return self.cameras.get(cid)
    
    def shutdown(self):
        self.is_system_running = False
        for c in self.cameras.values(): c.stop()
        if self.ai_process.is_alive(): self.ai_process.terminate()

camera_system = CameraSystem()